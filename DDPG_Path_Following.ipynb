{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/sohrab/.local/lib/python3.10/site-packages (24.2)\n",
      "Found existing installation: Shimmy 2.0.0\n",
      "Uninstalling Shimmy-2.0.0:\n",
      "  Successfully uninstalled Shimmy-2.0.0\n",
      "Found existing installation: stable-baselines3 1.7.0\n",
      "Uninstalling stable-baselines3-1.7.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 816, in move\n",
      "    os.rename(src, real_dst)\n",
      "PermissionError: [Errno 13] Permission denied: '/usr/local/lib/python3.10/dist-packages/stable_baselines3-1.7.0-py3.10.egg' -> '/tmp/pip-uninstall-ludb2olx'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/commands/uninstall.py\", line 106, in run\n",
      "    uninstall_pathset = req.uninstall(\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/req/req_install.py\", line 723, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/req/req_uninstall.py\", line 370, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/req/req_uninstall.py\", line 261, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/home/sohrab/.local/lib/python3.10/site-packages/pip/_internal/utils/misc.py\", line 354, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 834, in move\n",
      "    rmtree(src)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 725, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 658, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 681, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 679, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: 'RECORD'\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gymnasium==0.29.1\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/sohrab/.local/lib/python3.10/site-packages (from gymnasium==0.29.1) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages/cloudpickle-3.0.0-py3.10.egg (from gymnasium==0.29.1) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/sohrab/.local/lib/python3.10/site-packages (from gymnasium==0.29.1) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/sohrab/.local/lib/python3.10/site-packages (from gymnasium==0.29.1) (0.0.4)\n",
      "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gymnasium\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 1.0.0a2\n",
      "    Uninstalling gymnasium-1.0.0a2:\n",
      "      Successfully uninstalled gymnasium-1.0.0a2\n",
      "Successfully installed gymnasium-0.29.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting shimmy\n",
      "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/sohrab/.local/lib/python3.10/site-packages (from shimmy) (1.23.5)\n",
      "Collecting gymnasium>=1.0.0a1 (from shimmy)\n",
      "  Downloading gymnasium-1.0.0a2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages/cloudpickle-3.0.0-py3.10.egg (from gymnasium>=1.0.0a1->shimmy) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/sohrab/.local/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/sohrab/.local/lib/python3.10/site-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
      "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
      "Downloading gymnasium-1.0.0a2-py3-none-any.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.3/954.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gymnasium, shimmy\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 0.29.1\n",
      "    Uninstalling gymnasium-0.29.1:\n",
      "      Successfully uninstalled gymnasium-0.29.1\n",
      "Successfully installed gymnasium-1.0.0a2 shimmy-2.0.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages/stable_baselines3-1.7.0-py3.10.egg (1.7.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages/cloudpickle-3.0.0-py3.10.egg (from stable-baselines3[extra]) (3.0.0)\n",
      "Collecting gym==0.21 (from stable-baselines3[extra])\n",
      "  Using cached gym-0.21.0.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /home/sohrab/.local/lib/python3.10/site-packages/setuptools/_distutils/dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg)\n",
      "  \u001b[31m   \u001b[0m error in gym setup command: 'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip uninstall -y shimmy stable-baselines3 gymnasium\n",
    "!pip install gymnasium==0.29.1\n",
    "!pip install shimmy\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Tuple, Box, Discrete\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hec(psic,psid):\n",
    "    HE = psic - psid\n",
    "    if HE>1 :\n",
    "      HE = HE - 2\n",
    "    if HE<-1 :\n",
    "      HE = HE + 2\n",
    "    return HE\n",
    "\n",
    "def dist(x1,y1,x2,y2):\n",
    "    return np.sqrt((x1-x2)**2 + (y1-y2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent1() :\n",
    "\n",
    "    def __init__(self,xi, yi, psii, vi, dt) :\n",
    "        self.x = [xi]\n",
    "        self.y = [yi]\n",
    "        self.psi = [psii]\n",
    "        self.v = [vi]\n",
    "        self.dt = dt\n",
    "\n",
    "        self.polars = np.full((30,),0.0)\n",
    "\n",
    "\n",
    "    def kinematics(self,action,collision):\n",
    "        v_a = self.v[-1] + action[0]*0.1*self.dt\n",
    "        if v_a<0.2:\n",
    "          v_a=0.2\n",
    "        if v_a>1:\n",
    "          v_a = 1\n",
    "        if collision == True and v_a>0.5:\n",
    "          v_a = 0.5\n",
    "\n",
    "        psi_a = self.psi[-1] + action[1]*0.1*self.dt\n",
    "        if psi_a<-1:\n",
    "          psi_a= psi_a +2\n",
    "        if psi_a>1:\n",
    "          psi_a = psi_a - 2\n",
    "\n",
    "        x_a = self.x[-1] + 10*v_a*np.cos(np.pi*psi_a)*self.dt\n",
    "        y_a = self.y[-1] + 10*v_a*np.sin(np.pi*psi_a)*self.dt\n",
    "\n",
    "        self.x.append(x_a)\n",
    "        self.y.append(y_a)\n",
    "        self.psi.append(psi_a)\n",
    "        self.v.append(v_a)\n",
    "\n",
    "    def radar(self, list_obs, a):\n",
    "        k = 0\n",
    "        self.polars = np.full((30,),0.0)\n",
    "        angle = np.arange(self.psi[-1]-2/3,self.psi[-1]+2/3+0.01,4/15)\n",
    "        for i in range(5):\n",
    "            for j in angle:\n",
    "                x_point = self.x[-1] + (i+1)*a*np.cos(j*np.pi)\n",
    "                y_point = self.y[-1] + (i+1)*a*np.sin(j*np.pi)\n",
    "                for obstacle in list_obs :\n",
    "                    if dist(x_point, y_point, obstacle.x[-1], obstacle.y[-1])<= obstacle.r :\n",
    "                      self.polars[k] = 1\n",
    "                      break\n",
    "\n",
    "                k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Obstacle():\n",
    "    def __init__(self,xf,yf,dt,rad=20):\n",
    "        self.r = rad\n",
    "        self.x = [xf/2]\n",
    "        self.y = [yf/2]\n",
    "        self.v = np.random.randint(2,5)\n",
    "        self.direction = np.random.uniform(-np.pi,np.pi)\n",
    "        self.dt = dt\n",
    "\n",
    "    def kinematics(self):\n",
    "        x_a = self.x[-1] + self.v*np.cos(self.direction)*self.dt\n",
    "        y_a = self.y[-1] + self.v*np.sin(self.direction)*self.dt\n",
    "        self.direction = self.direction + np.random.uniform(-np.pi/6,np.pi/6)\n",
    "        self.x.append(x_a)\n",
    "        self.y.append(y_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reward(HE,v,polars,collision):\n",
    "\n",
    "    a = (-1)* abs(HE)\n",
    "\n",
    "    b = 0\n",
    "    radial_weights = [5,3,1.2,0.5,0.2]\n",
    "    k = 0\n",
    "    for i in range(5): #dis\n",
    "        for j in range(6): #angle\n",
    "            if polars[k]==1 :\n",
    "                b-=radial_weights[i]/60\n",
    "            k+=1\n",
    "\n",
    "    c = min(a,b)*v\n",
    "\n",
    "    d = 0\n",
    "    if collision :\n",
    "        d = -1\n",
    "\n",
    "    return 0.5*a + 0.1*b + 0.13*c+ 0.2*d + 0.15*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel.scatter_gather import T\n",
    "class CustomEnv(Env):\n",
    "    xfp = 0\n",
    "    yfp = 0\n",
    "    xp = []\n",
    "    yp = []\n",
    "    vp = []\n",
    "    lis = []\n",
    "\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\"]}\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.psi0 = np.random.uniform(-np.pi,np.pi)\n",
    "        self.xf = 500 * np.cos(self.psi0)\n",
    "        self.yf = 500 * np.sin(self.psi0)\n",
    "        self.del_t = 0.25\n",
    "        self.steps= 0\n",
    "\n",
    "        self.agent = Agent1(0,0,self.psi0,0.2,self.del_t)\n",
    "\n",
    "        self.list_obs = []\n",
    "        self.n_obs = np.random.randint(3,5)\n",
    "        for i in range(self.n_obs) :\n",
    "            obstacle = Obstacle((0.6*random.random()+0.2)*self.xf,\n",
    "                                (0.6*random.random()+0.2)*self.yf,\n",
    "                                self.del_t, 30)\n",
    "            self.list_obs.append(obstacle)\n",
    "\n",
    "        self.agent.radar(self.list_obs, 6)\n",
    "\n",
    "        self.collision = False\n",
    "        for obstacle in self.list_obs :\n",
    "            if dist(self.agent.x[-1],self.agent.y[-1], obstacle.x[-1], obstacle.y[-1])<=obstacle.r :\n",
    "              self.collision = True\n",
    "              break\n",
    "\n",
    "        self.done = False\n",
    "        self.cum_rew = []\n",
    "        self.epi_rew = 0\n",
    "\n",
    "\n",
    "        self.he = hec(self.agent.psi[-1], np.arctan2(self.yf-self.agent.y[-1], self.xf-self.agent.x[-1])/np.pi)\n",
    "        self.action_space = Box(low = np.array([-1,-1]), high = np.array([1,1]), shape = (2,), dtype = np.float32)\n",
    "        low = np.full((30,),0.0)\n",
    "        low = np.append(low,[-1,-1])\n",
    "        high = np.full((32,),1.0)\n",
    "        self.observation_space = Box(low=low, high=high, shape = (32,), dtype=np.float32)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        self.agent.kinematics(action, self.collision)\n",
    "        for obstacle in self.list_obs :\n",
    "            obstacle.kinematics()\n",
    "\n",
    "        self.agent.radar(self.list_obs, 10)\n",
    "\n",
    "        self.collision = False\n",
    "        for obstacle in self.list_obs :\n",
    "            if dist(self.agent.x[-1],self.agent.y[-1], obstacle.x[-1], obstacle.y[-1])<=obstacle.r :\n",
    "              self.collision = True\n",
    "              break\n",
    "\n",
    "\n",
    "\n",
    "        self.he = hec(self.agent.psi[-1], np.arctan2(self.yf-self.agent.y[-1], self.xf-self.agent.x[-1])/np.pi)\n",
    "        self.observation = np.array(np.append(self.agent.polars, [self.he, self.agent.v[-1]]),dtype = np.float32)\n",
    "\n",
    "        self.reward = Reward(self.he, self.agent.v[-1],self.agent.polars,self.collision)\n",
    "        self.epi_rew = self.reward + self.epi_rew\n",
    "\n",
    "        self.steps= self.steps + self.del_t\n",
    "\n",
    "        if dist(self.agent.x[-1],self.agent.y[-1],self.xf,self.yf) < 15:\n",
    "            self.done = True\n",
    "            self.render()\n",
    "\n",
    "\n",
    "        if self.steps>= 70 :\n",
    "            self.done = True\n",
    "            self.render()\n",
    "\n",
    "        if self.done == True:\n",
    "            self.cum_rew = np.append(self.cum_rew,self.epi_rew)\n",
    "\n",
    "        self.info = {}\n",
    "        return self.observation, self.reward, self.done,False, self.info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.i+=1\n",
    "        self.psi0 = np.random.uniform(-np.pi,np.pi)\n",
    "        self.xf = 500 * np.cos(self.psi0)\n",
    "        self.yf = 500 * np.sin(self.psi0)\n",
    "        self.del_t = 0.25\n",
    "        self.steps= 0\n",
    "\n",
    "        self.agent = Agent1(0,0,self.psi0/np.pi,0.2,self.del_t)\n",
    "\n",
    "        self.list_obs = []\n",
    "        self.n_obs = np.random.randint(3,5)\n",
    "        for i in range(self.n_obs) :\n",
    "            obstacle = obstacle = Obstacle((0.6*random.random()+0.2)*self.xf,\n",
    "                                          (0.6*random.random()+0.2)*self.yf,\n",
    "                                          self.del_t, 30)\n",
    "            self.list_obs.append(obstacle)\n",
    "\n",
    "        self.agent.radar(self.list_obs, 10)\n",
    "\n",
    "        self.collision = False\n",
    "        for obstacle in self.list_obs :\n",
    "            if dist(self.agent.x[-1],self.agent.y[-1], obstacle.x[-1], obstacle.y[-1])<=obstacle.r :\n",
    "              self.collision = True\n",
    "              break\n",
    "\n",
    "        self.epi_rew = 0\n",
    "\n",
    "        self.he = hec(self.agent.psi[-1], np.arctan2(self.yf-self.agent.y[-1], self.xf-self.agent.x[-1])/np.pi)\n",
    "\n",
    "        self.done = False\n",
    "\n",
    "        observation = np.array(np.append(self.agent.polars, [self.he, self.agent.v[-1]]),dtype = np.float32)\n",
    "        info = {}\n",
    "        return observation, info\n",
    "\n",
    "    def render(self):\n",
    "        self.xp = self.agent.x\n",
    "        self.yp = self.agent.y\n",
    "        self.vp = self.agent.v\n",
    "        self.xfp = self.xf\n",
    "        self.yfp = self.yf\n",
    "        self.lis = self.list_obs\n",
    "\n",
    "    def close(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(env):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(( min(0,env.xfp)-40, max(0,env.xfp)+40))\n",
    "    ax.set_ylim(( min(0,env.yfp)-40, max(0,env.yfp)+40))\n",
    "    ax.plot(env.xfp,env.yfp,'b.', ms = 3)\n",
    "\n",
    "\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_xlim(( min(0,env.xfp)-40, max(0,env.xfp)+40))\n",
    "        ax.set_ylim(( min(0,env.yfp)-40, max(0,env.yfp)+40))\n",
    "        ax.plot(env.xfp,env.yfp,'r*', ms = 8)\n",
    "        ax.set_title(f'Velocity: {env.vp[frame-1]}')\n",
    "\n",
    "\n",
    "        # draw circle around a point\n",
    "        for obstacle in env.lis :\n",
    "            Drawing_colored_circle = plt.Circle(( obstacle.x[frame-1], obstacle.y[frame-1]), obstacle.r, color='red', alpha=0.4)\n",
    "            ax.add_artist( Drawing_colored_circle )\n",
    "\n",
    "        # plot path follwed by ship\n",
    "        pt = ax.plot(env.xp[:frame], env.yp[:frame], color= 'black') # path of ship\n",
    "        ax.scatter(env.xp[frame-1],env.yp[frame-1],marker='>',color='black' ) # ship position\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "        ax.grid(True)\n",
    "\n",
    "\n",
    "    return animation.FuncAnimation(fig, update, frames = len(env.xp), interval=50, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Your environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv_checker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3-1.7.0-py3.10.egg/stable_baselines3/common/env_checker.py:334\u001b[0m, in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_env\u001b[39m(env: gym\u001b[38;5;241m.\u001b[39mEnv, warn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, skip_render_check: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    Check that an environment follows Gym API.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m    This is particularly useful when using a custom environment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m        True by default (useful for the CI)\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    335\u001b[0m         env, gym\u001b[38;5;241m.\u001b[39mEnv\n\u001b[1;32m    336\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# ============= Check the spaces (observation and action) ================\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     _check_spaces(env)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Your environment must inherit from the gym.Env class cf https://github.com/openai/gym/blob/master/gym/core.py"
     ]
    }
   ],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "policy_kwargs = dict(net_arch=[128,128])\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env,policy_kwargs = policy_kwargs, verbose=1)\n",
    "\n",
    "\n",
    "# obs = env.reset()\n",
    "# while True:\n",
    "#     action, _states = model.predict(obs, deterministic=True)\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "#     if done:\n",
    "#         obs = env.reset()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done,trun, info = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "anim = visualize(env)\n",
    "anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writervideo = animation.FFMpegWriter(fps=40)\n",
    "anim.save('vd_final.mp4', writer=writervideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"DDPG_sb3\")\n",
    "Episode_rewards = env.cum_rew\n",
    "plt.figure(figsize=(9,6))\n",
    "running_avg = np.empty(len(Episode_rewards))\n",
    "for t in range(len(Episode_rewards)):\n",
    "        running_avg[t] = np.mean(Episode_rewards[max(0, t-100):(t+1)])\n",
    "plt.plot(Episode_rewards[:600],color=\"teal\",alpha=0.2)\n",
    "plt.plot(running_avg,color=\"teal\",linewidth=2.0)\n",
    "plt.ylabel(\"Reward Units\")\n",
    "plt.xlabel(\"No. of Episode\")\n",
    "plt.title(\"Deep Deterministic Policy Gradient (DDPG)\")\n",
    "plt.grid()\n",
    "plt.savefig(\"DDPG_Rewards_waves_Nomoto.jpg\",dpi = 420)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
